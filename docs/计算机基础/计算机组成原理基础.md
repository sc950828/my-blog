## 计算机的工作原理

当我们输入数据的时候，cpu 里的控制器会让输入设备把这些指令存储到存储器(内存)上。

控制器分析指令之后，此时让存储器把数据发送到运算器里(控制器和运算器都在 cpu 里面)。这里需要注意，存储器既能存储数据，还能存储指令。

控制器控制运算器做数据的运算 并且将运算结果返回存储器。

控制器控制存储器将结果返回给输出设备。

## 计算机的计算单位

### 容量单位

1. bit 比特
2. Byte 字节 1Byte = 8bit
3. KB 千字节 1KB = 1024 Byte
4. MB 兆字节 1MB = 1024 KB
5. GB 吉字节 1GB = 1024 MB
6. TB 太字节 1TB = 1024 GB
7. PB 拍字节 1PB = 1024 TB
8. EB 艾字节 1EB = 1024 PB

#### 为什么网上买的移动硬盘 500G 格式化之后只剩 465G 呢？

因为硬盘商一般用十进制标记容量 也就是 1GB 等于 1000MB。

`(500 * 1000 * 1000 * 1000) / (1024 * 1024 * 1024) = 465`

### 网络速度单位 M

光纤 100M 就是 100M/s= 100Mbps = 100Mbit/s

#### 为什么 100M 光纤下载速度最大只有 12M 每秒

100Mbit/s = (100/8)MB/s = 12.5MB/s

### CPU 速度单位 Hz

Hz 其实就是秒分之一。就是每秒钟周期性变动重复次数的计量。人耳能听到 20Hz-20000Hz

1GHz = 1000<sup>3</sup>Hz

## 计算机字符集与字符编码

计算机中储存的信息都是用二进制数表示的；而我们在屏幕上看到的英文、汉字等字符是二进制数转换之后的结果。通俗的说，按照何种规则将字符存储在计算机中，如'a'用什么表示，称为"编码"；反之，将存储在计算机中的二进制数解析显示出来，称为"解码"，如同密码学中的加密和解密。在解码过程中，如果使用了错误的解码规则，则导致'a'解析成'b'或者乱码。

### 位 bit

数据存储的最小单位。每个二进制数字 0 或者 1 就是 1 个位；

### 字节 byte

8 个位构成一个字节；即：1 byte (字节)= 8 bit(位)

### 字符

汉字、字母、数字、符号等都是字符。一般 utf-8 编码下，一个汉字 字符 占用 3 个 字节；一般 gbk 编码下，一个汉字 字符 占用 2 个 字节；

### 字符集

字符集（Charset）：是一个系统支持的所有抽象字符的集合。字符是各种文字和符号的总称，包括各国家文字、标点符号、图形符号、数字等。

### 字符编码

字符编码（Character Encoding）：是一套法则，使用该法则能够对字符集进行转换。转换为计算机可以接受的数字系统的数，称为数字代码。也就是二进制。

### 常用字符集

常见字符集名称：ASCII 字符集、GB2312 字符集、BIG5 字符集、GB18030 字符集、Unicode 字符集等。计算机要准确的处理各种字符集文字，需要进行字符编码，以便计算机能够识别和存储各种文字。

### ASCII

#### ASCII 字符集

ASCII 字符集包含 128 个字符

#### ASCII 编码

ASCII 编码：将 ASCII 字符集转换为计算机可以接受的数字系统的数的规则。使用 7 位（bits）表示一个字符，共 128 字符，所以 7 位编码的字符集只能支持 128 个字符。2<sup>7</sup> = 128

### ASCII 扩展

#### ASCII 扩展字符集

为了表示更多的欧洲常用字符对 ASCII 进行了扩展。ASCII 扩展字符集包括 256 个字符

#### ASCII 扩展编码

ASCII 扩展编码：将 ASCII 扩展字符集转换为计算机可以接受的数字系统的数的规则。ASCII 扩展字符集使用 8 位（bits）表示一个字符，共 256 字符。2<sup>8</sup> = 256

### GB2312

#### GB2312 字符集

是第一个中文编码集。一共收录了 7445 个字符，包括了 6763 个汉字和 682 个其他符号。但是没有包含其他国家字符。

#### GB2312 编码

专家把那些 127 号之后的奇异符号们（即 EASCII）取消掉，规定：一个小于 127 的字符的意义与原来相同，但两个大于 127 的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从 0xA1 用到 0xF7，后面一个字节（低字节）从 0xA1 到 0xFE，这样我们就可以组合出大约 7000 多个简体汉字了。在这些编码里，还把数学符号、罗马希腊的 字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的"全角"字符，而原来在 127 号以下的那些就叫"半角"字符了。

### GBK

#### GBK 字符集

1. 收录了 21003 个汉字，支持全部中日韩文字
2. 向下兼容了 GB2312
3. 但是不符合国际标准

#### GBK 编码

微软利用 GB2312 未使用的编码空间，收录 GB13000.1-93 全部字符制定了 GBK 编码。

### Unicode

当计算机传到世界各个国家时，为了适合当地语言和字符，设计和实现类似 GB232/GBK/GB18030/BIG5 的编码方案。这样各搞一套，在本地使用没有问题，一旦出现在网络中，由于不兼容，互相访问就出现了乱码现象。

#### Unicode 字符集

Unicode 字符集定义了世界通用的符号集。Unicode 已经包含了超过十万个字符。被称为统一码、万国码。

#### Unicode 编码

`UTF-*`实现了编码，有 UTF-8、UTF-16/UTF-32

### 中断

在程序运行过程中，系统出现了一个必须由 CPU 立即处理的情况，此时，CPU 暂时中止程序的执行转而处理这个新的情况的过程就叫做中断。

- "用户态 ---> 核心态"是通过中断实现的。并且中断是唯一途径。
- "核心态 ---> 用户态"的切换时通过执行一个特权指令，将程序状态的标志位设为用户态。

中断分为内中断和外中断

- 内中断常见的情况如程序非法操作(比如你要拿的的数据的内存地址不是内存地址，是系统无法识别的地址)，地址越界(比如系统给你的程序分配了一些内存，但是你访问的时候超出了你应该访问的内存范围)、浮点溢出(比如系统只能表示 1.1 到 5.1 的范围，你输入一个 100, 超出了计算机能处理的范围)，或者异常，陷入 trap（是指应用程序请求系统调用造成的，什么是系统调用）。
- 外中断常见的情况如 I/O 中断（由 I/O 控制器产生，用于发送信号通知操作完成等信号，比如进程需要请求打印机资源，打印机有一个启动准备的过程，准备好了就会给 CPU 一个 I/O 中断，告诉它已经准备好了）、时钟中断（由处理器内部的计时器产生，允许操作系统以一定规程执行函数，操作系统每过大约 15ms 会进行一次线程调度，就是利用时钟中断来实现的）。

### 阻塞非阻塞 轮询

操作系统中对于 I/O 只有两种处理方式，即阻塞和非阻塞。

阻塞 I/O 即为调用之后需要等待完成所有操作后，调用才结束，这就造成了 CPU 一直在等待 I/O 结束，处理能力得不到充分利用。

非阻塞 I/O 在调用之后会立即返回，之后 CPU 可以去处理其他事务。但由于 I/O 并没有完成，立即返回的仅仅是调用的状态，为了获取最终结果，应用程序需要充分调用判断操作是否完成，即轮询。

常见的轮询技术

- read 这是最原始的一种，通过重复调用来读取最终结果，在得到结果之前，CPU 会一直消耗在等待上。
- select 在 read 基础上做了改进，通过对文件描述符上的事件状态来进行判断，当用户进程调用了 select，那么整个进程会被 block，而同时，kernel 会「监视」所有 select 负责的 socket，当任何一个 socket 中的数据准备好了，select 就会返回，这个时候用户进程再调用 read 操作，将数据从 kernel 拷贝到用户进程。select 和之后的 poll、epoll 也称为 I/O 多路复用。select 采用一个长度为 1024 的数组来存储状态，所以最多可以同时检查 1024 个文件描述符。
- poll 采用链表方式避免数组长度的限制，性能有所改善。
- epoll 这是 Linux 下效率最高的 I/O 事件通知机制，在进入轮询时如果没有检查到 I/O 事件，将会进行休眠，直到事件发生将它唤醒，不会浪费 CPU。
- kqueue 实现方式与 epoll 类似，仅在 BSD 系统下存在。
